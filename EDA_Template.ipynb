{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df(df):\n",
    "    print(df.shape)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12721a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b01c6b00",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "Creating new conda environment and installing nessary libraries\n",
    "\n",
    "*pip install -r /path/requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5add27c",
   "metadata": {},
   "source": [
    "## Importing nessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To visualise all the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data set from csv file & printing first 5 data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c56caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"Mixed_dataset.csv\"\n",
    "target_feature = 'SalePrice'\n",
    "final_model_name = 'LinearRegression_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_filename)\n",
    "print_df(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c3d27",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5d0a8",
   "metadata": {},
   "source": [
    "##### Dataset shape / dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ebf6f",
   "metadata": {},
   "source": [
    "##### Exploring Dataset Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4817b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97705746",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c71d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf3c1e",
   "metadata": {},
   "source": [
    "##### Checking missing / null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking is there any feature has null values\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sum of null/missing values in the featue\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b52669",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the percentage of nan/null/missing values present in each feature\n",
    "features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n",
    "\n",
    "for feature in features_with_na:\n",
    "    print(feature, round(dataset[feature].isnull().mean() * 100,2) ,  ' % missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c923874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null data in the dataset\n",
    "null_data = dataset[dataset.isnull().any(axis=1)]\n",
    "print_df(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d063581",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_na_against_total_dataset = round((null_data.shape[0] / dataset.shape[0]) * 100 ,2)\n",
    "print('percentage of na data against total dataset {} % '.format(percentage_of_na_against_total_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a9636",
   "metadata": {},
   "source": [
    "### Plotting null record columns as heatmap & Marrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dataset.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5635468",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4550c9",
   "metadata": {},
   "source": [
    "### visualizing the featues which has null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62539afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the na/null features\n",
    "\n",
    "null_dataset = dataset[features_with_na]\n",
    "\n",
    "cat_feature = get_categorical_features(null_dataset)\n",
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    visualize_barplot(null_dataset,feature)\n",
    "yr_feature = set(get_date_features(null_dataset))\n",
    "num_yr_feature = set(get_numerical_features(null_dataset))\n",
    "num_feature = num_yr_feature - yr_feature\n",
    "for feature in num_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    plot_numeric(dataset,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a566ab2",
   "metadata": {},
   "source": [
    "### Visualization of categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8965b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of categorical Variables using matplotlib barplot\n",
    "def visualize_barplot(df , variable,x_axis =None , y_axis=None,title=None):\n",
    "    df[variable].value_counts().plot(kind='bar', title= title,grid=True)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of categorical Variables using sns countplot\n",
    "def plot_sns_cat_feature(df , variable,x_axis =None , y_axis=None,title=None):\n",
    "#     print(df[variable].value_counts())\n",
    "    ax = sns.countplot(x=variable, data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of categorical Variables using sns count plot with 2 variable\n",
    "def plot_sns_cat_feature_with_target(df , variable, target_feature ,x_axis =None , y_axis=None,title=None):\n",
    "    ax = sns.countplot(x=target_feature, hue=variable, data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a98c2c",
   "metadata": {},
   "source": [
    "### Visualization of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of of Numerical Variables using sns distplot \n",
    "def plot_sns_numeric_feature(df,variable ,x_axis =None , y_axis=None,title=None):\n",
    "    sns.distplot(df[variable], kde=False, bins=15,grid=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32600fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Numerical Variables using matplotlib histogram \n",
    "def plot_numeric(df,variable ,x_axis =None , y_axis=None,title=None):\n",
    "    plt.hist(df[variable], bins = 20)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO visualize the features in histogram\n",
    "dataset.hist(figsize=(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fectching features list based on the feature data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b873fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categorical features\n",
    "def get_categorical_features(df):\n",
    "    categorical_features = [feature for feature in df.columns if df[feature].dtypes == 'O']\n",
    "    print('Number of categorical features : ', len(categorical_features))\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab426cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical features\n",
    "def get_numerical_features(df):\n",
    "    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "    print('Number of numerical features : ', len(numerical_features))\n",
    "    return numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc094e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of date features\n",
    "def get_date_features(df):\n",
    "    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "    year_feature = [feature for feature in numerical_features if 'Yr' in feature or 'yr' in feature or 'Year' in feature or 'year' in feature]\n",
    "    print('Number of date features: ', len(year_feature))\n",
    "    return year_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae9d18",
   "metadata": {},
   "source": [
    "### visualizing the data to find the missing value based on the target value ( Only for Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb999493",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature , \" vs \" , target_feature)\n",
    "#     plot_sns_cat_feature_with_target(null_dataset,feature,target_feature)\n",
    "    plot_sns_cat_feature_with_target(dataset,feature,target_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb8cb8",
   "metadata": {},
   "source": [
    "##### Finding unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d35a95",
   "metadata": {},
   "source": [
    "##### Checking dataset descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4499d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including only string columns in a DataFrame\n",
    "df.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7908dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including only categorical columns from a DataFrame\n",
    "df.describe(include=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3add3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fe7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd911308",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20155415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping feature\n",
    "df.drop(feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the missing values\n",
    "df.dropna(axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f23ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the missing values with mean , median , mode\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "dataset[feature].fillna(dataset[feature].mean(),inplace=True)\n",
    "dataset[feature].fillna(dataset[feature].median(),inplace=True)\n",
    "dataset[feature].fillna(dataset[feature].mode(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaafc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing missing values using Imputer (Univariate variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "dataset_features_na_imputed = imputer.fit_transform(df[features_with_na])\n",
    "dataset_features_na_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing missing values using IterativeImputer ( Multivariate feature imputation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputer.fit(X)\n",
    "dataset_features_na_imputed = np.round(imputer.transform(df[features_with_na]))\n",
    "dataset_features_na_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing missing values using KNNImputer ( Nearest neighbors imputation )\n",
    "# add knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "dataset_features_na_imputed = imputer.fit_transform(X)\n",
    "dataset_features_na_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c14b",
   "metadata": {},
   "source": [
    "### Outliers / Noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2654c87",
   "metadata": {},
   "source": [
    "## Numerical features are in 2 types\n",
    "### Discrete features\n",
    "### Continous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b593f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving Discrete features from numerical features\n",
    "def get_discrete_features_from_numerical(df):\n",
    "    yr_feature = set(get_date_features(df))\n",
    "    num_yr_feature = set(get_numerical_features(df))\n",
    "    num_feature = num_yr_feature - yr_feature    \n",
    "    discrete_feature=[feature for feature in num_feature if len(df[feature].unique())<10 and feature not in year_feature]\n",
    "    print(\"Discrete features Count: {}\".format(len(discrete_feature)))\n",
    "    return discrete_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df150248",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving Continous features from numerical features\n",
    "def get_continous_features_from_numerical(df):\n",
    "    yr_feature = set(get_date_features(df))\n",
    "    num_yr_feature = set(get_numerical_features(df))\n",
    "    num_feature = num_yr_feature - yr_feature  \n",
    "    discrete_feature = get_discrete_features_from_numerical(df)\n",
    "    continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature + year_feature]\n",
    "    print(\"Continuous features Count {}\".format(len(continuous_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b417a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0020381",
   "metadata": {},
   "source": [
    "# Visualizing the all features for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d959acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the na/null features\n",
    "\n",
    "X_dataset = dataset.drop([target_feature], axis = 1)\n",
    "\n",
    "cat_feature = get_categorical_features(X_dataset)\n",
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    visualize_barplot(X_dataset,feature)\n",
    "yr_feature = set(get_date_features(X_dataset))\n",
    "num_yr_feature = set(get_numerical_features(X_dataset))\n",
    "num_feature = num_yr_feature - yr_feature\n",
    "for feature in num_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    plot_numeric(X_dataset,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    print('The feature is {} and number of categories are {}'.format(feature,dataset[feature].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b49e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde for bell curve\n",
    "sns.histplot(df.column_name , kde =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ea99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distrubution plot\n",
    "\n",
    "sns.distplot(df.column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ba8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mean for the feaure data\n",
    "dataset.groupby(feature).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b52886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting target variable to numberic if its categorical feature with binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Y': 1, 'N': 0}\n",
    "df[target_feature] = df[target_feature].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dataset = dataset[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot features against target variable\n",
    "plot_sns_cat_feature(Y_dataset,target_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4bacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3628732d",
   "metadata": {},
   "source": [
    "# Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling with default data points and creating new dataset which will be used for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e190f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = df[df.target_feature == 0]\n",
    "class_1 = df[df.target_feature == 1]\n",
    "print(class_0.shape , class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a129ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number sampling\n",
    "class_0_sample = class_0.sample(n=452)\n",
    "class_0_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([class_0_sample,class_1],axis=0)\n",
    "new_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample. (c_data[c_data.columns[1:]], c_data[c_data.columns[0]])\n",
    "usampled_df = X.assign(Churn = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302843b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X, y = ros.fit_resample(X, y);\n",
    "output = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19c1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting continuous values in to discreate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_data = Binarizer().fit_transform(dataset[continuous_feature])\n",
    "binarized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlation b/w the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db622ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(dataset.corr(), fmt='.2f',annot = True, cmap = 'RdYlGn')\n",
    "# ax = sns.heatmap(corr, xticklabels = corr.columns, yticklabels = corr.columns,linewidths = 0.2, cmap = 'YlGnBu', annot = True)\n",
    "# sns.heatmap(corr , cbar = True , square = True , fmt = '.1f' , annot = True , annot_kws = { 'size' : 8} , cmap = 'Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de188ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset , x_vars = x_columns , y_vars = y_column , kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue = target_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6459c5",
   "metadata": {},
   "source": [
    "## Encoding categorical data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5c3bc",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "\n",
    "#### Label Encoder will replace every categorical variable with number. Useful for replacing yes by 1, no by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2407a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder = LabelEncoder()\n",
    "cat_feature_encoded = lable_encoder.fit_transform(dataset['categorical_feature'])\n",
    "cat_feature_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f848302",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45229dc",
   "metadata": {},
   "source": [
    "## One hot encoder\n",
    "\n",
    "#### One Hot Encoder will create a separate column for every variable and give a value of 1 where the variable is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609dc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded = one_hot_encoder.fit_transform(dataset['categorical_feature'])\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a337276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a22ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cdaa6e6",
   "metadata": {},
   "source": [
    "## Pandas funtion get_dummies\n",
    "\n",
    "#### Same like One Hot Encoder, It will create a separate column for every variable and give a value of 1 where the variable is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoded = pd.get_dummies(dataset['categorical_feature'])\n",
    "cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0f112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d76539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af7bbd0d",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Its the one of the data trasformation technique to make data all in resanable rage for easy caculation\n",
    "\n",
    "#### There are 3 most used ways to scale features. \n",
    "1. __Min Max Scaling__: \n",
    "Will scale the input to have minimum of 0 and maximum of 1. That is, it scales the data in the range of [0, 1] This is useful when the parameters have to be on same positive scale. But in this case, the outliers are lost. \n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "2. __Standardization__:\n",
    "Will scale the input to have mean of 0 and variance of 1. \n",
    "$$X_{stand} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "3. __Normalizing__: \n",
    "Will scale the input to make the norm of 1. For instance, for 3D data the 3 independent variables will lie on a unit Sphere. \n",
    "\n",
    "4. __Log Transformation__:\n",
    "Taking the log of data after any of above transformation. \n",
    "\n",
    "5. __Decimal scaling__:\n",
    "Converting data in to a dicimal for of largest data point\n",
    "\n",
    "For most applications, Standardization is recommended. Min Max Scaling is recommended for Neural Networks. Normalizing is recommended when Clustering eg. KMeans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cbcf3",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standardized_dataset = standard_scaler.fit_transform(X)\n",
    "standardized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27437a0d",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef2778",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "normolized_dataset = normalizer.fit_transform(X)\n",
    "normolized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74de9b",
   "metadata": {},
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaled_dataset = min_max_scaler.fit_transform(X)\n",
    "min_max_scaled_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52fb23a",
   "metadata": {},
   "source": [
    "### Decimal Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe00e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1978f7a9",
   "metadata": {},
   "source": [
    "### Log Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bb4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ela0989540"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304d48b",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c889eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Feature Selection\n",
    "# first, I specify the Lasso Regression model, and I\n",
    "# select a suitable alpha (equivalent of penalty).\n",
    "# The bigger the alpha the less features that will be selected.\n",
    "\n",
    "# Then I use the selectFromModel object from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d02148",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print the number of total and selected features\n",
    "\n",
    "# this is how we can make a list of the selected features\n",
    "selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
    "\n",
    "# let's print some stats\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat\n",
    "X_train=X_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9450b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19d0436d",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Different plot design\n",
    "\n",
    "### plt.plot(x,y, 'r+')\n",
    "### plt.plot(x,y, 'g')\n",
    "### plt.plot(x,y, 'g*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot( x_feature , y_feature ,df ):\n",
    "    plt.plot(df.x_feature , df.y_feature)\n",
    "    plt.title( x_feature + ' vs ' + y_feature)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_2data( x_feature , y_feature , df ,df1= None):\n",
    "    plt.plot(df.x_feature , df.y_feature)\n",
    "    plt.plot(df1.x_feature , df1.y_feature)\n",
    "    plt.title( x_feature + ' vs ' + y_feature)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot():    \n",
    "    plt.bar(x,top_10_populated_countries.population / 10 **6 )\n",
    "    plt.xlabel('country raking wise')\n",
    "    plt.ylabel('population')\n",
    "    plt.xticks(x,top_10_populated_countries.country , rotation = \"vertical\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(x_feature , y_feature ,df):\n",
    "    plt.scatter(df.x_feature , df.y_feature , 10 )\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(label,data):\n",
    "    fig1 = plt.figure()\n",
    "    ax = fig1.add_axes([0,0,1,1])  \n",
    "    ax.pie(data,labels=label , autopct = '%1.1f%%' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac0af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc6fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
