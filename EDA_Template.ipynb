{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df(df):\n",
    "    print(df.shape)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff379d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67208dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930463b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c306e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429734db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b9cf32",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "Creating new conda environment and installing nessary libraries\n",
    "\n",
    "*pip install -r /path/requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b319929",
   "metadata": {},
   "source": [
    "## Importing nessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To visualise all the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce24248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data set from csv file & printing first 5 data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"Mixed_dataset.csv\"\n",
    "target_feature = 'SalePrice'\n",
    "final_model_name = 'LinearRegression_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_filename)\n",
    "print_df(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c81733",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a019c1",
   "metadata": {},
   "source": [
    "##### Dataset shape / dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ddfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe764d",
   "metadata": {},
   "source": [
    "##### Exploring Dataset Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29240b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4c62a",
   "metadata": {},
   "source": [
    "##### Checking missing / null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2931881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking is there any feature has null values\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3aa581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sum of null/missing values in the featue\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the percentage of nan/null/missing values present in each feature\n",
    "features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n",
    "\n",
    "for feature in features_with_na:\n",
    "    print(feature, round(dataset[feature].isnull().mean() * 100,2) ,  ' % missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fabd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null data in the dataset\n",
    "null_data = dataset[dataset.isnull().any(axis=1)]\n",
    "print_df(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_na_against_total_dataset = round((null_data.shape[0] / dataset.shape[0]) * 100 ,2)\n",
    "print('percentage of na data against total dataset {} % '.format(percentage_of_na_against_total_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf7b402",
   "metadata": {},
   "source": [
    "### Plotting null record columns as heatmap & Marrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dataset.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8856da9c",
   "metadata": {},
   "source": [
    "### visualizing the featues which has null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the na/null features\n",
    "\n",
    "null_dataset = dataset[features_with_na]\n",
    "\n",
    "cat_feature = get_categorical_features(null_dataset)\n",
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    visualize_barplot(null_dataset,feature)\n",
    "yr_feature = set(get_date_features(null_dataset))\n",
    "num_yr_feature = set(get_numerical_features(null_dataset))\n",
    "num_feature = num_yr_feature - yr_feature\n",
    "for feature in num_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    plot_numeric(dataset,feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514fcf6",
   "metadata": {},
   "source": [
    "### Visualization of categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of categorical Variables using matplotlib barplot\n",
    "def visualize_barplot(df , variable,x_axis =None , y_axis=None,title=None):\n",
    "    df[variable].value_counts().plot(kind='bar', title= title,grid=True)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of categorical Variables using sns countplot\n",
    "def plot_sns_cat_feature(df , variable,x_axis =None , y_axis=None,title=None):\n",
    "#     print(df[variable].value_counts())\n",
    "    ax = sns.countplot(x=variable, data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of categorical Variables using sns count plot with 2 variable\n",
    "def plot_sns_cat_feature_with_target(df , variable, target_feature ,x_axis =None , y_axis=None,title=None):\n",
    "    ax = sns.countplot(x=target_feature, hue=variable, data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2c547",
   "metadata": {},
   "source": [
    "### Visualization of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of of Numerical Variables using sns distplot \n",
    "def plot_sns_numeric_feature(df,variable ,x_axis =None , y_axis=None,title=None):\n",
    "    sns.distplot(df[variable], kde=False, bins=15,grid=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be996f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Numerical Variables using matplotlib histogram \n",
    "def plot_numeric(df,variable ,x_axis =None , y_axis=None,title=None):\n",
    "    plt.hist(df[variable], bins = 20)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO visualize the features in histogram\n",
    "dataset.hist(figsize=(15, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fectching features list based on the feature data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categorical features\n",
    "def get_categorical_features(df):\n",
    "    categorical_features = [feature for feature in df.columns if df[feature].dtypes == 'O']\n",
    "    print('Number of categorical features : ', len(categorical_features))\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical features\n",
    "def get_numerical_features(df):\n",
    "    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "    print('Number of numerical features : ', len(numerical_features))\n",
    "    return numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of date features\n",
    "def get_date_features(df):\n",
    "    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "    year_feature = [feature for feature in numerical_features if 'Yr' in feature or 'yr' in feature or 'Year' in feature or 'year' in feature]\n",
    "    print('Number of date features: ', len(year_feature))\n",
    "    return year_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f88c55",
   "metadata": {},
   "source": [
    "### visualizing the data to find the missing value based on the target value ( Only for Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature , \" vs \" , target_feature)\n",
    "#     plot_sns_cat_feature_with_target(null_dataset,feature,target_feature)\n",
    "    plot_sns_cat_feature_with_target(dataset,feature,target_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01970",
   "metadata": {},
   "source": [
    "##### Finding unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d081d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf84b2a",
   "metadata": {},
   "source": [
    "##### Checking dataset descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df95cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including only string columns in a DataFrame\n",
    "df.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including only categorical columns from a DataFrame\n",
    "df.describe(include=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b950ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bf9ff",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cde450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45929ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping feature\n",
    "df.drop(feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the missing values\n",
    "df.dropna(axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the missing values with mean , median , mode\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "dataset[feature].fillna(dataset[feature].mean(),inplace=True)\n",
    "dataset[feature].fillna(dataset[feature].median(),inplace=True)\n",
    "dataset[feature].fillna(dataset[feature].mode(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing missing values using Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "dataset_features_na_imputed = imputer.fit_transform(df[features_with_na])\n",
    "dataset_features_na_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7299b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing missing values using IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit(X)\n",
    "print(np.round(imp.transform(df[features_with_na])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e962aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3618885d",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460940ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54aaa9d",
   "metadata": {},
   "source": [
    "## Numerical features are in 2 types\n",
    "### Discrete features\n",
    "### Continous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving Discrete features from numerical features\n",
    "def get_discrete_features_from_numerical(df):\n",
    "    yr_feature = set(get_date_features(df))\n",
    "    num_yr_feature = set(get_numerical_features(df))\n",
    "    num_feature = num_yr_feature - yr_feature    \n",
    "    discrete_feature=[feature for feature in num_feature if len(df[feature].unique())<10 and feature not in year_feature]\n",
    "    print(\"Discrete features Count: {}\".format(len(discrete_feature)))\n",
    "    return discrete_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd384a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving Continous features from numerical features\n",
    "def get_continous_features_from_numerical(df):\n",
    "    yr_feature = set(get_date_features(df))\n",
    "    num_yr_feature = set(get_numerical_features(df))\n",
    "    num_feature = num_yr_feature - yr_feature  \n",
    "    discrete_feature = get_discrete_features_from_numerical(df)\n",
    "    continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature + year_feature]\n",
    "    print(\"Continuous features Count {}\".format(len(continuous_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6556f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7da7a45",
   "metadata": {},
   "source": [
    "# Visualizing the all features for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a90e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the na/null features\n",
    "\n",
    "X_dataset = dataset.drop([target_feature], axis = 1)\n",
    "\n",
    "cat_feature = get_categorical_features(X_dataset)\n",
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    visualize_barplot(X_dataset,feature)\n",
    "yr_feature = set(get_date_features(X_dataset))\n",
    "num_yr_feature = set(get_numerical_features(X_dataset))\n",
    "num_feature = num_yr_feature - yr_feature\n",
    "for feature in num_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    plot_numeric(X_dataset,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb170b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d95e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    print('The feature is {} and number of categories are {}'.format(feature,dataset[feature].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde for bell curve\n",
    "sns.histplot(df.column_name , kde =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distrubution plot\n",
    "\n",
    "sns.distplot(df.column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mean for the feaure data\n",
    "dataset.groupby(feature).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting target variable to numberic if its categorical feature with binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Y': 1, 'N': 0}\n",
    "df[target_feature] = df[target_feature].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dataset = dataset[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1685dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot features against target variable\n",
    "plot_sns_cat_feature(Y_dataset,target_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571fda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c977b10",
   "metadata": {},
   "source": [
    "# Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc00be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling with default data points and creating new dataset which will be used for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c52dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = df[df.target_feature == 0]\n",
    "class_1 = df[df.target_feature == 1]\n",
    "print(class_0.shape , class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number sampling\n",
    "class_0_sample = class_0.sample(n=452)\n",
    "class_0_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4595039",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([class_0_sample,class_1],axis=0)\n",
    "new_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd42bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample. (c_data[c_data.columns[1:]], c_data[c_data.columns[0]])\n",
    "usampled_df = X.assign(Churn = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14f169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X, y = ros.fit_resample(X, y);\n",
    "output = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76daab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7441bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting continuous values in to discreate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_data = Binarizer().fit_transform(dataset[continuous_feature])\n",
    "binarized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlation b/w the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96339b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(dataset.corr(), fmt='.2f',annot = True, cmap = 'RdYlGn')\n",
    "# ax = sns.heatmap(corr, xticklabels = corr.columns, yticklabels = corr.columns,linewidths = 0.2, cmap = 'YlGnBu', annot = True)\n",
    "# sns.heatmap(corr , cbar = True , square = True , fmt = '.1f' , annot = True , annot_kws = { 'size' : 8} , cmap = 'Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue = target_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c2fc8",
   "metadata": {},
   "source": [
    "## Encoding categorical data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808bc108",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "\n",
    "#### Label Encoder will replace every categorical variable with number. Useful for replacing yes by 1, no by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder = LabelEncoder()\n",
    "cat_feature_encoded = lable_encoder.fit_transform(dataset['categorical_feature'])\n",
    "cat_feature_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e73b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1cd17b",
   "metadata": {},
   "source": [
    "## One hot encoder\n",
    "\n",
    "#### One Hot Encoder will create a separate column for every variable and give a value of 1 where the variable is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6096d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded = one_hot_encoder.fit_transform(dataset['categorical_feature'])\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380ff06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52cfb43e",
   "metadata": {},
   "source": [
    "## Pandas funtion get_dummies\n",
    "\n",
    "#### Same like One Hot Encoder, It will create a separate column for every variable and give a value of 1 where the variable is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoded = pd.get_dummies(dataset['categorical_feature'])\n",
    "cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3594d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fffef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54020e62",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Its the one of the data trasformation technique to make data all in resanable rage for easy caculation\n",
    "\n",
    "#### There are 3 most used ways to scale features. \n",
    "1. __Min Max Scaling__: \n",
    "Will scale the input to have minimum of 0 and maximum of 1. That is, it scales the data in the range of [0, 1] This is useful when the parameters have to be on same positive scale. But in this case, the outliers are lost. \n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "2. __Standardization__:\n",
    "Will scale the input to have mean of 0 and variance of 1. \n",
    "$$X_{stand} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "3. __Normalizing__: \n",
    "Will scale the input to make the norm of 1. For instance, for 3D data the 3 independent variables will lie on a unit Sphere. \n",
    "\n",
    "4. __Log Transformation__:\n",
    "Taking the log of data after any of above transformation. \n",
    "\n",
    "5. __Decimal scaling__:\n",
    "Converting data in to a dicimal for of largest data point\n",
    "\n",
    "For most applications, Standardization is recommended. Min Max Scaling is recommended for Neural Networks. Normalizing is recommended when Clustering eg. KMeans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86e74f",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standardized_dataset = standard_scaler.fit_transform(X)\n",
    "standardized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e5b327",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ae94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "normolized_dataset = normalizer.fit_transform(X)\n",
    "normolized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063c436",
   "metadata": {},
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaled_dataset = min_max_scaler.fit_transform(X)\n",
    "min_max_scaled_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fe629",
   "metadata": {},
   "source": [
    "### Decimal Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6108b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e716301e",
   "metadata": {},
   "source": [
    "### Log Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8120ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de5cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a751383",
   "metadata": {},
   "outputs": [],
   "source": [
    "ela0989540"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f177fc",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Feature Selection\n",
    "# first, I specify the Lasso Regression model, and I\n",
    "# select a suitable alpha (equivalent of penalty).\n",
    "# The bigger the alpha the less features that will be selected.\n",
    "\n",
    "# Then I use the selectFromModel object from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0eeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print the number of total and selected features\n",
    "\n",
    "# this is how we can make a list of the selected features\n",
    "selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
    "\n",
    "# let's print some stats\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7495f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat\n",
    "X_train=X_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7262b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45bd26e4",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Different plot design\n",
    "\n",
    "### plt.plot(x,y, 'r+')\n",
    "### plt.plot(x,y, 'g')\n",
    "### plt.plot(x,y, 'g*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e696e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot( x_feature , y_feature ,df ):\n",
    "    plt.plot(df.x_feature , df.y_feature)\n",
    "    plt.title( x_feature + ' vs ' + y_feature)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7491bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_2data( x_feature , y_feature , df ,df1= None):\n",
    "    plt.plot(df.x_feature , df.y_feature)\n",
    "    plt.plot(df1.x_feature , df1.y_feature)\n",
    "    plt.title( x_feature + ' vs ' + y_feature)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot():    \n",
    "    plt.bar(x,top_10_populated_countries.population / 10 **6 )\n",
    "    plt.xlabel('country raking wise')\n",
    "    plt.ylabel('population')\n",
    "    plt.xticks(x,top_10_populated_countries.country , rotation = \"vertical\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe58207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(x_feature , y_feature ,df):\n",
    "    plt.scatter(df.x_feature , df.y_feature , 10 )\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(label,data):\n",
    "    fig1 = plt.figure()\n",
    "    ax = fig1.add_axes([0,0,1,1])  \n",
    "    ax.pie(data,labels=label , autopct = '%1.1f%%' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076f021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
