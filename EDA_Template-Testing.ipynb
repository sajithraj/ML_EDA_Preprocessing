{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084b7955",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "Creating new conda environment and installing nessary libraries\n",
    "\n",
    "*pip install -r /path/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f713d9",
   "metadata": {},
   "source": [
    "## Importing nessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To visualise all the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772aec6d",
   "metadata": {},
   "source": [
    "## Importing data set from csv file & printing first 5 data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"Mixed_dataset.csv\"\n",
    "target_feature = 'SalePrice'\n",
    "final_model_name = 'LinearRegression_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_filename)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f6b84",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023b7a3",
   "metadata": {},
   "source": [
    "##### Dataset shape / dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a973a",
   "metadata": {},
   "source": [
    "##### Exploring Dataset Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dda4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3d246",
   "metadata": {},
   "source": [
    "##### Checking missing / null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a38af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking is there any feature has null values\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Sum of null/missing values in the featue\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the percentage of nan/null/missing values present in each feature\n",
    "\n",
    "features_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n",
    "\n",
    "for feature in features_with_na:\n",
    "    print(feature, round(dataset[feature].isnull().mean() * 100,2) ,  ' % missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Number of rows that has null values\n",
    "null_data = dataset[dataset.isnull().any(axis=1)]\n",
    "print(null_data.shape)\n",
    "null_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1439bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of na/null row data against total dataset\n",
    "percentage_of_na_against_total_dataset = round((null_data.shape[0] / dataset.shape[0]) * 100 ,2)\n",
    "print('percentage of na data against total dataset {} % '.format(percentage_of_na_against_total_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d660a58",
   "metadata": {},
   "source": [
    "### Plotting null record columns as heatmap & Marrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32421a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dataset.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e2772",
   "metadata": {},
   "source": [
    "### visualizing the featues which has null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the na/null features\n",
    "\n",
    "null_dataset = dataset[features_with_na]\n",
    "\n",
    "cat_feature = get_categorical_features(null_dataset)\n",
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    visualize_barplot(null_dataset,feature)\n",
    "yr_feature = set(get_date_features(null_dataset))\n",
    "num_yr_feature = set(get_numerical_features(null_dataset))\n",
    "num_feature = num_yr_feature - yr_feature\n",
    "for feature in num_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    plot_numeric(dataset,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ecbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of categorical Variables\n",
    "def visualize_barplot(df , variable,x_axis =None , y_axis=None,title=None):\n",
    "    df[variable].value_counts().plot(kind='bar', title= title,grid=True)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of categorical Variables\n",
    "def plot_sns_cat_feature(df , variable,x_axis =None , y_axis=None,title=None):\n",
    "#     print(df[variable].value_counts())\n",
    "    ax = sns.countplot(x=variable, data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4975df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of 2 categorical Variables\n",
    "def plot_sns_cat_feature_with_target(df , variable, target_feature ,x_axis =None , y_axis=None,title=None):\n",
    "    ax = sns.countplot(x=variable, hue=target_feature, data=df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1742a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Numerical Variables\n",
    "def plot_sns_numeric_feature(df,variable ,x_axis =None , y_axis=None,title=None):\n",
    "    sns.distplot(df[variable], kde=False, bins=15,grid=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff139f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Numerical Variables\n",
    "def plot_numeric(df,variable ,x_axis =None , y_axis=None,title=None):\n",
    "    plt.hist(df[variable], bins = 20)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categorical features\n",
    "def get_categorical_features(df):\n",
    "    categorical_features = [feature for feature in df.columns if df[feature].dtypes == 'O']\n",
    "    print('Number of categorical features : ', len(categorical_features))\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a72174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical features\n",
    "def get_numerical_features(df):\n",
    "    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "    print('Number of numerical features : ', len(numerical_features))\n",
    "    return numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of date features\n",
    "def get_date_features(df):\n",
    "    numerical_features = [feature for feature in df.columns if df[feature].dtypes != 'O']\n",
    "    year_feature = [feature for feature in numerical_features if 'Yr' in feature or 'yr' in feature or 'Year' in feature or 'year' in feature]\n",
    "    print('Number of date features: ', len(year_feature))\n",
    "    return year_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0cfc8",
   "metadata": {},
   "source": [
    "### visualizing the data to find the missing value based on the target value ( Only for Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature , \" vs \" , target_feature)\n",
    "#     plot_sns_cat_feature_with_target(null_dataset,feature,target_feature)\n",
    "    plot_sns_cat_feature_with_target(dataset,feature,target_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4070b292",
   "metadata": {},
   "source": [
    "##### Checking dataset descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8353c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb10f50",
   "metadata": {},
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ec794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping feature\n",
    "df.drop(feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fc55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing missing values using Imputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "dataset_features_na_imputed = imputer.fit_transform(df[features_with_na])\n",
    "dataset_features_na_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414611a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b75238cc",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd8a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ec393bb",
   "metadata": {},
   "source": [
    "## Numerical features are in 2 types\n",
    "### Discrete features\n",
    "### Continous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving Discrete features from numerical features\n",
    "def get_discrete_features_from_numerical(df):\n",
    "    yr_feature = set(get_date_features(df))\n",
    "    num_yr_feature = set(get_numerical_features(df))\n",
    "    num_feature = num_yr_feature - yr_feature    \n",
    "    discrete_feature=[feature for feature in num_feature if len(df[feature].unique())<10 and feature not in year_feature]\n",
    "    print(\"Discrete features Count: {}\".format(len(discrete_feature)))\n",
    "    return discrete_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d38358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deriving Continous features from numerical features\n",
    "def get_continous_features_from_numerical(df):\n",
    "    yr_feature = set(get_date_features(df))\n",
    "    num_yr_feature = set(get_numerical_features(df))\n",
    "    num_feature = num_yr_feature - yr_feature  \n",
    "    discrete_feature = get_discrete_features_from_numerical(df)\n",
    "    continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature + year_feature]\n",
    "    print(\"Continuous features Count {}\".format(len(continuous_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d14fd",
   "metadata": {},
   "source": [
    "# Visualizing the all features for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the na/null features\n",
    "\n",
    "X_dataset = dataset.drop([target_feature], axis = 1)\n",
    "\n",
    "cat_feature = get_categorical_features(X_dataset)\n",
    "for feature in cat_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    visualize_barplot(X_dataset,feature)\n",
    "yr_feature = set(get_date_features(X_dataset))\n",
    "num_yr_feature = set(get_numerical_features(X_dataset))\n",
    "num_feature = num_yr_feature - yr_feature\n",
    "for feature in num_feature:\n",
    "    print(\"Visualization of \" , feature)\n",
    "    plot_numeric(X_dataset,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_features:\n",
    "    print('The feature is {} and number of categories are {}'.format(feature,dataset[feature].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7db53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde for bell curve\n",
    "sns.histplot(df.column_name , kde =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ebaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distrubution plot\n",
    "\n",
    "sns.distplot(df.column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06244c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting target variable to numberic if its categorical feature with binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55de725",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Y': 1, 'N': 0}\n",
    "df[target_feature] = df[target_feature].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac365a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dataset = dataset[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753afb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1fe090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot features against target variable\n",
    "plot_sns_cat_feature(Y_dataset,target_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1050c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "987a58bd",
   "metadata": {},
   "source": [
    "# Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling with default data points and creating new dataset which will be used for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = df[df.target_feature == 0]\n",
    "class_1 = df[df.target_feature == 1]\n",
    "print(class_0.shape , class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_sample = class_0.sample(n=452)\n",
    "class_0_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([class_0_sample,class_1],axis=0)\n",
    "new_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample. (c_data[c_data.columns[1:]], c_data[c_data.columns[0]])\n",
    "usampled_df = X.assign(Churn = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3dc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X, y = ros.fit_resample(X, y);\n",
    "output = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d9b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a96f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting continuous values in to discreate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_data = Binarizer().fit_transform(dataset[continuous_feature])\n",
    "binarized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a45e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the correlation b/w the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23261852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(dataset.corr(), annot = True, cmap = 'RdYlGn')\n",
    "# ax = sns.heatmap(corr, xticklabels = corr.columns, yticklabels = corr.columns,linewidths = 0.2, cmap = 'YlGnBu', annot = True)\n",
    "# sns.heatmap(corr , cbar = True , square = True , fmt = '.1f' , annot = True , annot_kws = { 'size' : 8} , cmap = 'Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835221d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue = 'Exited')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72f6b6",
   "metadata": {},
   "source": [
    "## Encoding categorical data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fcd7f7",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "\n",
    "#### Label Encoder will replace every categorical variable with number. Useful for replacing yes by 1, no by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder = LabelEncoder()\n",
    "cat_feature_encoded = lable_encoder.fit_transform(dataset['categorical_feature'])\n",
    "cat_feature_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab4d40",
   "metadata": {},
   "source": [
    "## One hot encoder\n",
    "\n",
    "#### One Hot Encoder will create a separate column for every variable and give a value of 1 where the variable is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded = one_hot_encoder.fit_transform(dataset['categorical_feature'])\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e219eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21361abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df51dd0c",
   "metadata": {},
   "source": [
    "## Pandas funtion get_dummies\n",
    "\n",
    "#### Same like One Hot Encoder, It will create a separate column for every variable and give a value of 1 where the variable is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoded = pd.get_dummies(dataset['categorical_feature'])\n",
    "cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec29918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287f48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eaa31d8",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Its the one of the data trasformation technique to make data all in resanable rage for easy caculation\n",
    "\n",
    "#### There are 3 most used ways to scale features. \n",
    "1. __Min Max Scaling__: \n",
    "Will scale the input to have minimum of 0 and maximum of 1. That is, it scales the data in the range of [0, 1] This is useful when the parameters have to be on same positive scale. But in this case, the outliers are lost. \n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "2. __Standardization__:\n",
    "Will scale the input to have mean of 0 and variance of 1. \n",
    "$$X_{stand} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "3. __Normalizing__: \n",
    "Will scale the input to make the norm of 1. For instance, for 3D data the 3 independent variables will lie on a unit Sphere. \n",
    "\n",
    "4. __Log Transformation__:\n",
    "Taking the log of data after any of above transformation. \n",
    "\n",
    "5. __Decimal scaling__:\n",
    "Converting data in to a dicimal for of largest data point\n",
    "\n",
    "For most applications, Standardization is recommended. Min Max Scaling is recommended for Neural Networks. Normalizing is recommended when Clustering eg. KMeans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c923c1",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standardized_dataset = standard_scaler.fit_transform(X)\n",
    "standardized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596e0ab",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af449812",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "normolized_dataset = normalizer.fit_transform(X)\n",
    "normolized_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc1df3",
   "metadata": {},
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaled_dataset = min_max_scaler.fit_transform(X)\n",
    "min_max_scaled_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfbf653",
   "metadata": {},
   "source": [
    "### Decimal Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450329c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc56a25",
   "metadata": {},
   "source": [
    "### Log Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03266aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4808627",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ce4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Feature Selection\n",
    "# first, I specify the Lasso Regression model, and I\n",
    "# select a suitable alpha (equivalent of penalty).\n",
    "# The bigger the alpha the less features that will be selected.\n",
    "\n",
    "# Then I use the selectFromModel object from sklearn, which\n",
    "# will select the features which coefficients are non-zero\n",
    "\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82424444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's print the number of total and selected features\n",
    "\n",
    "# this is how we can make a list of the selected features\n",
    "selected_feat = X_train.columns[(feature_sel_model.get_support())]\n",
    "\n",
    "# let's print some stats\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat\n",
    "X_train=X_train[selected_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a041a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c072e8",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55677d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Different plot design\n",
    "\n",
    "### plt.plot(x,y, 'r+')\n",
    "### plt.plot(x,y, 'g')\n",
    "### plt.plot(x,y, 'g*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot( x_feature , y_feature ,df ):\n",
    "    plt.plot(df.x_feature , df.y_feature)\n",
    "    plt.title( x_feature + ' vs ' + y_feature)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2251c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_2data( x_feature , y_feature , df ,df1= None):\n",
    "    plt.plot(df.x_feature , df.y_feature)\n",
    "    plt.plot(df1.x_feature , df1.y_feature)\n",
    "    plt.title( x_feature + ' vs ' + y_feature)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot():    \n",
    "    plt.bar(x,top_10_populated_countries.population / 10 **6 )\n",
    "    plt.xlabel('country raking wise')\n",
    "    plt.ylabel('population')\n",
    "    plt.xticks(x,top_10_populated_countries.country , rotation = \"vertical\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320963b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(x_feature , y_feature ,df):\n",
    "    plt.scatter(df.x_feature , df.y_feature , 10 )\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(label,data):\n",
    "    fig1 = plt.figure()\n",
    "    ax = fig1.add_axes([0,0,1,1])  \n",
    "    ax.pie(data,labels=label , autopct = '%1.1f%%' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833498b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "743d8c38",
   "metadata": {},
   "source": [
    "# Tuning parameters and finding best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d21f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1335ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model, param_grid, n_jobs=-1)\n",
    "%time clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4675f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc672aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffca53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaludate a score by cross-validation\n",
    "scores = cross_val_score(clf, X, y, n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6edd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9235d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicting the testdata with trained model\n",
    "1\n",
    "test_pred = clf.predict(X_test)\n",
    "Classification scores & Model Evaluation\n",
    "1\n",
    "# Finding accuracy\n",
    "2\n",
    "metrics.accuracy_score(y_test ,test_pred)\n",
    "1\n",
    "# Finding confusion matrix\n",
    "2\n",
    "metrics.confusion_matrix(y_test, test_pred)\n",
    "1\n",
    "# Finding precision score\n",
    "2\n",
    "metrics.precision_score(y_test, test_pred, average='macro')\n",
    "l\n",
    "1\n",
    "# Finding recall score\n",
    "2\n",
    "metrics.recall_score(y_test, test_pred,average='macro')\n",
    "1\n",
    "# Finding classification report\n",
    "2\n",
    "print(metrics.classification_report(y_test, test_pred))\n",
    "1\n",
    "# Finding precision recall fscore support\n",
    "2\n",
    "metrics.precision_recall_fscore_support(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48211755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b64c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaludation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c14c9a",
   "metadata": {},
   "source": [
    "# Load model\n",
    "\n",
    "saving the model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "\n",
    "pickle.dump(model, open(final_model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "\n",
    "loaded_model = pickle.load(open(final_model_name, 'rb'))\n",
    "\n",
    "predictions = loaded_model.predict(test_data)\n",
    "5\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "language": "python",
   "name": "python38232bit2b054411f44e4a01b4413efad7e2020a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
